{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from heapq import nlargest\n",
    "import pandas as pd\n",
    "from CharVectorizer import CharVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загружаем таблицы с признаками**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cons_table = pd.read_csv('cons_table.csv', encoding='UTF-8', na_filter = True, header=None, chunksize=1)\n",
    "\n",
    "vocs_table = pd.read_csv('voc_table.csv', encoding='UTF-8', na_filter = True, header=None, chunksize=1)\n",
    "\n",
    "cons_line = []\n",
    "for line in cons_table:\n",
    "    cons_line.append(line)\n",
    "vocs_line = []\n",
    "for line in vocs_table:\n",
    "    vocs_line.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letter_vec = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Векторизируем признаки. Словарь формата {'слово' : 'вектор признаков'}**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CharVectorizer(\"bƀcdðfghjklmnpqrstuvwxzȥaâáäæiîíúüûyoöœóôeéêę\")\n",
    "\n",
    "for i in range(len(vocs_line)):\n",
    "    word = vocs_line[i][1] + vocs_line[i][2] + vocs_line[i][3]\n",
    "    windows = [word[i]]\n",
    "    vec = vectorizer.transform(windows, 100)\n",
    "    letter_vec[vocs_line[i][0][i]] = vec\n",
    "\n",
    "letter_vec['a'].sum(), letter_vec['y'].sum()\n",
    "\n",
    "for i in range(len(cons_line)):\n",
    "    word = cons_line[i][1] + cons_line[i][2] + cons_line[i][3]\n",
    "    windows = [word[i]]\n",
    "    vec = vectorizer.transform(windows, 100)\n",
    "    letter_vec[cons_line[i][0][i]] = vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Иголка **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pt ={'match': 1.5, 'mismatch': -1, 'gap': -1, 'dif_first': -2}\n",
    "\n",
    "def mch(alpha, beta):\n",
    "    if alpha == beta:\n",
    "        sim = pt['match']\n",
    "        fake_sim = pt['match']\n",
    "    \n",
    "    elif alpha == '-' or beta == '-':\n",
    "        if alpha == 'h' or beta == 'h':\n",
    "            sim, fake_sim = 0, 0\n",
    "        else:\n",
    "            sim = pt['gap']\n",
    "            fake_sim = pt['gap']\n",
    "    \n",
    "    else:\n",
    "        sim = float(str(cosine_similarity(letter_vec[alpha], letter_vec[beta])).strip('[]'))-1\n",
    "        #fake_sim = int(float(str(cosine_similarity(letter_vec[alpha], letter_vec[beta])).strip('[]'))-1)\n",
    "        fake_sim = pt['mismatch']\n",
    "        \n",
    "    return sim, fake_sim\n",
    "\n",
    "def needle(s1, s2):\n",
    "    m, n = len(s1), len(s2)\n",
    "    score = np.zeros((m+1, n+1))\n",
    "    \n",
    "    #Initialization\n",
    "    for i in range(m+1):\n",
    "        score[i][0] = pt['gap'] * i\n",
    "    for j in range(n+1):\n",
    "        score[0][j] = pt['gap'] * j\n",
    "    \n",
    "    #Fill\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if i == 1 and j == 1 and s1[i-1] != s2[j-1]:\n",
    "                diag = score[i-1][j-1] + pt['dif_first']\n",
    "            else:\n",
    "                diag = score[i-1][j-1] + mch(s1[i-1], s2[j-1])[1]\n",
    "            delete = score[i-1][j] + pt['gap']\n",
    "            insert = score[i][j-1] + pt['gap']\n",
    "            score[i][j] = max(diag, delete, insert)\n",
    "\n",
    "    align1, align2 = '', ''\n",
    "    i,j = m,n\n",
    "    \n",
    "    #Traceback\n",
    "    while i > 0 and j > 0:\n",
    "        score_current = score[i][j]\n",
    "        score_diag = score[i-1][j-1]\n",
    "        score_left = score[i][j-1]\n",
    "        score_up = score[i-1][j]\n",
    "        if score_current == score_left + pt['gap']:\n",
    "            a1,a2 = '-',s2[j-1]\n",
    "            j -= 1\n",
    "        elif score_current == score_up + pt['gap']:\n",
    "            a1,a2 = s1[i-1],'-'\n",
    "            i -= 1\n",
    "        elif score_current == score_diag + mch(s1[i-1], s2[j-1])[1]:\n",
    "            a1,a2 = s1[i-1],s2[j-1]\n",
    "            i,j = i-1,j-1\n",
    "        elif i == 1 and j == 1 and s1[i-1] != s2[j-1] and score_current == score_diag + pt['dif_first']:\n",
    "            a1,a2 = s1[i-1],s2[j-1]\n",
    "            i,j = i-1,j-1\n",
    "        align1 += a1\n",
    "        align2 += a2\n",
    "            \n",
    "\n",
    "    while i > 0:\n",
    "        a1,a2 = s1[i-1],'-'\n",
    "        align1 += a1\n",
    "        align2 += a2\n",
    "        i -= 1\n",
    "        \n",
    "    while j > 0:\n",
    "        a1,a2 = '-',s2[j-1]\n",
    "        align1 += a1\n",
    "        align2 += a2\n",
    "        j -= 1\n",
    "    \n",
    "    align1 = align1[::-1]\n",
    "    align2 = align2[::-1]\n",
    "    seqN = len(align1)\n",
    "    sym = ''\n",
    "    seq_score = 0\n",
    "    true_score = []\n",
    "    ident = 0\n",
    "    for i in range(seqN):\n",
    "        a1 = align1[i]\n",
    "        a2 = align2[i]\n",
    "        if a1 == a2:\n",
    "            sym += a1\n",
    "            ident += 1\n",
    "            seq_score += mch(a1, a2)[1]\n",
    "            true_score.append(mch(a1, a2)[0])\n",
    "    \n",
    "        else: \n",
    "            if i == 1:\n",
    "                seq_score += pt['dif_first']\n",
    "                true_score.append(pt['dif_first'])\n",
    "            else:\n",
    "                seq_score += mch(a1, a2)[1]\n",
    "                true_score.append(mch(a1, a2)[0])\n",
    "            sym += ' '\n",
    "        \n",
    "    if align1[-2:] == '--' or align2[-2:] == '--': true_score[-1] += 2\n",
    "    elif align1[-1:] == '--' or align2[-1:] == '--': true_score[-1] += 1\n",
    "    return true_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5, -2, 1.5, -1, 1.5, -0.22999999999999998, -0.20999999999999996, -1, -1, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needle('argikmuk', 'aerbgze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.71, 6.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(needle('folkes', 'folgen')), sum(needle('folkes', 'folk'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Данные для кластеризации **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open ('norm_words.txt') as f:\n",
    "    words = f.read().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('prefix_with_gi.csv', encoding = 'UTF-8').read()\n",
    "prefs = []\n",
    "\n",
    "f = re.split('\\n', file)\n",
    "prefs = []\n",
    "for i in f:\n",
    "    n = re.sub(',', ' ', i)\n",
    "    n = re.sub('  ', ' ', n)\n",
    "    if n != '':\n",
    "        prefs.append(' '.join(n.rsplit()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = open('dictionary.html', encoding = \"UTF-8\")\n",
    "dictionary = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "tokenized_dict = []\n",
    "for txt in dictionary.find_all('strong'):\n",
    "    a = re.sub(r'\\(.*?\\)','',txt.text)\n",
    "    a = re.sub(r'\\W','', a)\n",
    "    tokenized_dict.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_words = []\n",
    "for lemma_raw in words:\n",
    "    lemma = ''\n",
    "    for l in prefs:\n",
    "        if l in lemma_raw:\n",
    "            lemma = lemma_raw.strip(l)\n",
    "            norm_words.append(lemma)\n",
    "            break\n",
    "    if lemma == '':\n",
    "        norm_words.append(lemma_raw)\n",
    "norm_words = list(filter(None, norm_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3840"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Обработка и запись **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3840, 3698)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dict), len(set(tokenized_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_dict = list(set(tokenized_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_dict.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TD = defaultdict(list)\n",
    "for i in tokenized_dict:\n",
    "    if len(i) > 0:\n",
    "        TD[i[0]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "dict_with_norms = {}\n",
    "for w in tqdm(range(len(norm_words))):\n",
    "    try:\n",
    "        word = norm_words[w].lower()\n",
    "        scores = {}\n",
    "        if len(word) > 0:\n",
    "            for i in tqdm(TD[word[0]], leave=False):\n",
    "                if abs(len(word) - len(i)) <= 4:\n",
    "                    score = sum(needle(word, i.lower()))\n",
    "                    scores[i] = score\n",
    "            if len(scores) > 0:\n",
    "                dict_with_norms[word] = scores\n",
    "                result[word] = max(dict_with_norms[word], key=dict_with_norms[word].get)\n",
    "        else:\n",
    "            print (word)\n",
    "    except:\n",
    "        print ('Exc', word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_result = {}\n",
    "for word in result:\n",
    "    if result[word] in true_result:\n",
    "        true_result[result[word]].append(word)\n",
    "    else:\n",
    "        true_result[result[word]] = [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('result.csv', mode='w', encoding = 'UTF-8') as f:\n",
    "    file = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    for word in true_result:\n",
    "        file.writerow([word, true_result[word]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
